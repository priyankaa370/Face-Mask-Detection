{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFSqkTCdWKMI"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awjrpqy-6MaQ"
      },
      "source": [
        "For setup, we need to mount and import from the Google drive since this notebook can only run in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DonPwAS_04sN",
        "outputId": "b37b0b89-981f-46d5-ac74-c0be996befe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3UGXxUii5Ym"
      },
      "source": [
        "### Installation\n",
        "\n",
        "\n",
        "> We need to install the tensorflow version '2.7.0' along with tf_slim library\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGL97-GXjSUw",
        "outputId": "4b6382b6-10f1-49e3-93c8-ae6fea0787b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.7.0\n",
            "  Downloading tensorflow-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 489.6 MB 25 kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.3.0)\n",
            "Collecting keras<2.8,>=2.7.0rc0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 49.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[K     |████████████████████████████████| 463 kB 45.8 MB/s \n",
            "\u001b[?25hCollecting gast<0.5.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (4.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.0.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (14.0.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.25.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.8.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.44.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.14.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.7.0) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (57.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (3.2.0)\n",
            "Installing collected packages: tensorflow-estimator, keras, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "Successfully installed gast-0.4.0 keras-2.7.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0\n",
            "Collecting tf_slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U --pre tensorflow==\"2.7.0\"\n",
        "!pip install tf_slim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_ap_s9ajTHH"
      },
      "source": [
        "Then we will install `pycocotools`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg8ZyA47i3pY",
        "outputId": "3c7b5ab9-a795-40d8-b6a0-0eea09e3ba63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (2.0.4)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pycocotools) (1.21.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.0->pycocotools) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pycocotools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vsOL3QR6kqs"
      },
      "source": [
        "Then we need to get `tensorflow/models` or `cd` to parent directory of the repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykA0c-om51s1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "497289db-ee7c-499a-b615-567c8288675a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3335, done.\u001b[K\n",
            "remote: Counting objects: 100% (3335/3335), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2760/2760), done.\u001b[K\n",
            "remote: Total 3335 (delta 885), reused 1382 (delta 525), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3335/3335), 34.32 MiB | 26.11 MiB/s, done.\n",
            "Resolving deltas: 100% (885/885), done.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O219m6yWAj9l"
      },
      "source": [
        "Once we compile protobufs, later we must install the object_detection package which can be seen in the next lines of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PY41vdYYNlXc"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd /content/models/research\n",
        "protoc object_detection/protos/*.proto --python_out=."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s62yJyQUcYbp",
        "outputId": "3d2af4b4-5007-4d8c-db55-53d82aed806c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/models/research\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.38.0-cp37-cp37m-manylinux2010_x86_64.whl (10.2 MB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.28)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n",
            "Collecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.25.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.4 MB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.7.0)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "Collecting tensorflow-text~=2.8.0\n",
            "  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "Collecting tensorflow~=2.8.0\n",
            "  Downloading tensorflow-2.8.0-cp37-cp37m-manylinux2010_x86_64.whl (497.5 MB)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.6)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Collecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.2.0)\n",
            "Collecting keras\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.25.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.44.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.4.11-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.6.8-cp37-cp37m-manylinux_2_24_x86_64.whl (253 kB)\n",
            "Collecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.20.3-py3-none-any.whl (46 kB)\n",
            "Collecting cloudpickle<3,>=2.0.0\n",
            "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Collecting protobuf>=3.12.0\n",
            "  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.12)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.7.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.7.0)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1692480 sha256=33754957a69f8ddba08b1c623058dadc7b0ab833e765cbd97eaff785e9ece9ee\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mwl0atw9/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n",
            "  Building wheel for py-cpuinfo (setup.py): started\n",
            "  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=9f9c1c1de18179fa7b790f4db9b610f2174e5393bdbd311a601fbdd1a3143a38\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for dill (setup.py): started\n",
            "  Building wheel for dill (setup.py): finished with status 'done'\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=63e57ca2fa6361144029b313c12a434626444e1f1abeb7dfdb619a4f70ca060e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py): started\n",
            "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=e151490f6b3e5d1c78ae7538bcc9f6dffc7896f53e90d6862888b80146552eb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=3c0f613c8abf35b37979a03917e515443ba9ff1db29b7e05ee8f227d8c48ff43\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n",
            "Installing collected packages: requests, protobuf, tf-estimator-nightly, keras, tensorflow, portalocker, dill, colorama, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.7.0\n",
            "    Uninstalling keras-2.7.0:\n",
            "      Successfully uninstalled keras-2.7.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.1.1\n",
            "    Uninstalling pymongo-4.1.1:\n",
            "      Successfully uninstalled pymongo-4.1.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "Successfully installed apache-beam-2.38.0 avro-python3-1.10.2 cloudpickle-2.0.0 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.11 hdfs-2.7.0 keras-2.8.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.5.64 orjson-3.6.8 portalocker-2.4.0 proto-plus-1.20.3 protobuf-3.20.1 py-cpuinfo-8.0.0 pymongo-3.12.3 pyyaml-5.4.1 requests-2.27.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-2.8.0 tensorflow-addons-0.16.1 tensorflow-io-0.25.0 tensorflow-model-optimization-0.7.2 tensorflow-text-2.8.2 tf-estimator-nightly-2.8.0.dev2021122109 tf-models-official-2.8.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cd /content/models/research\n",
        "python -m pip install ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBdjK2G5ywuc"
      },
      "source": [
        "### Importing necessary packages and modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hV4P5gyTWKMI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5FNuiRPWKMN"
      },
      "source": [
        "Now, import the object detection module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-IMl4b6BdGO"
      },
      "outputs": [],
      "source": [
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYPCiag2iz_q"
      },
      "source": [
        "Patches:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF-YlMl8c_bM"
      },
      "outputs": [],
      "source": [
        "# patch tf1 into `utils.ops`\n",
        "utils_ops.tf = tf.compat.v1\n",
        "\n",
        "# Patch the location of gfile\n",
        "tf.gfile = tf.io.gfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ai8pLZZWKMS"
      },
      "source": [
        "## Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zm8xp-0eoItE"
      },
      "outputs": [],
      "source": [
        "def load_model(model_name):\n",
        "  base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
        "  model_file = model_name + '.tar.gz'\n",
        "  model_dir = tf.keras.utils.get_file(\n",
        "    fname=model_name,\n",
        "    origin=base_url + model_file,\n",
        "    untar=True)\n",
        "\n",
        "  model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
        "\n",
        "  model = tf.saved_model.load(str(model_dir))\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1MVVTcLWKMW"
      },
      "source": [
        "## Loading label map\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDbpHkiWWKMX"
      },
      "outputs": [],
      "source": [
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = '/content/drive/MyDrive/TF2/object_detection/images/labelmap.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG-zn5ykWKMd",
        "outputId": "64c7cffe-e735-4ab2-eb20-2b0fea298244"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/content/drive/MyDrive/TF2/object_detection/images/test/GettyImages-1207592068-crop-650aaba.jpg')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "PATH_TO_TEST_IMAGES_DIR = pathlib.Path('/content/drive/MyDrive/TF2/object_detection/images/test')\n",
        "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"GettyImages-1207592068-crop-650aaba.jpg\")))\n",
        "TEST_IMAGE_PATHS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0_1AGhrWKMc"
      },
      "source": [
        "# Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7aOtOlebK7h"
      },
      "source": [
        "First, we need to load an object detection model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XNT0wxybKR6"
      },
      "outputs": [],
      "source": [
        "#model_name = 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8'\n",
        "#detection_model = load_model(model_name)\n",
        "detection_model = tf.saved_model.load('/content/drive/MyDrive/TF2/object_detection/Inference_graph/saved_model')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(detection_model.signatures['serving_default'].inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93oKcyYHlDxu",
        "outputId": "1783e16d-870f-40d0-be52-58548dc12151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Tensor 'input_tensor:0' shape=(1, None, None, 3) dtype=uint8>, <tf.Tensor 'unknown:0' shape=() dtype=resource>, <tf.Tensor 'unknown_0:0' shape=() dtype=resource>, <tf.Tensor 'unknown_1:0' shape=() dtype=resource>, <tf.Tensor 'unknown_2:0' shape=() dtype=resource>, <tf.Tensor 'unknown_3:0' shape=() dtype=resource>, <tf.Tensor 'unknown_4:0' shape=() dtype=resource>, <tf.Tensor 'unknown_5:0' shape=() dtype=resource>, <tf.Tensor 'unknown_6:0' shape=() dtype=resource>, <tf.Tensor 'unknown_7:0' shape=() dtype=resource>, <tf.Tensor 'unknown_8:0' shape=() dtype=resource>, <tf.Tensor 'unknown_9:0' shape=() dtype=resource>, <tf.Tensor 'unknown_10:0' shape=() dtype=resource>, <tf.Tensor 'unknown_11:0' shape=() dtype=resource>, <tf.Tensor 'unknown_12:0' shape=() dtype=resource>, <tf.Tensor 'unknown_13:0' shape=() dtype=resource>, <tf.Tensor 'unknown_14:0' shape=() dtype=resource>, <tf.Tensor 'unknown_15:0' shape=() dtype=resource>, <tf.Tensor 'unknown_16:0' shape=() dtype=resource>, <tf.Tensor 'unknown_17:0' shape=() dtype=resource>, <tf.Tensor 'unknown_18:0' shape=() dtype=resource>, <tf.Tensor 'unknown_19:0' shape=() dtype=resource>, <tf.Tensor 'unknown_20:0' shape=() dtype=resource>, <tf.Tensor 'unknown_21:0' shape=() dtype=resource>, <tf.Tensor 'unknown_22:0' shape=() dtype=resource>, <tf.Tensor 'unknown_23:0' shape=() dtype=resource>, <tf.Tensor 'unknown_24:0' shape=() dtype=resource>, <tf.Tensor 'unknown_25:0' shape=() dtype=resource>, <tf.Tensor 'unknown_26:0' shape=() dtype=resource>, <tf.Tensor 'unknown_27:0' shape=() dtype=resource>, <tf.Tensor 'unknown_28:0' shape=() dtype=resource>, <tf.Tensor 'unknown_29:0' shape=() dtype=resource>, <tf.Tensor 'unknown_30:0' shape=() dtype=resource>, <tf.Tensor 'unknown_31:0' shape=() dtype=resource>, <tf.Tensor 'unknown_32:0' shape=() dtype=resource>, <tf.Tensor 'unknown_33:0' shape=() dtype=resource>, <tf.Tensor 'unknown_34:0' shape=() dtype=resource>, <tf.Tensor 'unknown_35:0' shape=() dtype=resource>, <tf.Tensor 'unknown_36:0' shape=() dtype=resource>, <tf.Tensor 'unknown_37:0' shape=() dtype=resource>, <tf.Tensor 'unknown_38:0' shape=() dtype=resource>, <tf.Tensor 'unknown_39:0' shape=() dtype=resource>, <tf.Tensor 'unknown_40:0' shape=() dtype=resource>, <tf.Tensor 'unknown_41:0' shape=() dtype=resource>, <tf.Tensor 'unknown_42:0' shape=() dtype=resource>, <tf.Tensor 'unknown_43:0' shape=() dtype=resource>, <tf.Tensor 'unknown_44:0' shape=() dtype=resource>, <tf.Tensor 'unknown_45:0' shape=() dtype=resource>, <tf.Tensor 'unknown_46:0' shape=() dtype=resource>, <tf.Tensor 'unknown_47:0' shape=() dtype=resource>, <tf.Tensor 'unknown_48:0' shape=() dtype=resource>, <tf.Tensor 'unknown_49:0' shape=() dtype=resource>, <tf.Tensor 'unknown_50:0' shape=() dtype=resource>, <tf.Tensor 'unknown_51:0' shape=() dtype=resource>, <tf.Tensor 'unknown_52:0' shape=() dtype=resource>, <tf.Tensor 'unknown_53:0' shape=() dtype=resource>, <tf.Tensor 'unknown_54:0' shape=() dtype=resource>, <tf.Tensor 'unknown_55:0' shape=() dtype=resource>, <tf.Tensor 'unknown_56:0' shape=() dtype=resource>, <tf.Tensor 'unknown_57:0' shape=() dtype=resource>, <tf.Tensor 'unknown_58:0' shape=() dtype=resource>, <tf.Tensor 'unknown_59:0' shape=() dtype=resource>, <tf.Tensor 'unknown_60:0' shape=() dtype=resource>, <tf.Tensor 'unknown_61:0' shape=() dtype=resource>, <tf.Tensor 'unknown_62:0' shape=() dtype=resource>, <tf.Tensor 'unknown_63:0' shape=() dtype=resource>, <tf.Tensor 'unknown_64:0' shape=() dtype=resource>, <tf.Tensor 'unknown_65:0' shape=() dtype=resource>, <tf.Tensor 'unknown_66:0' shape=() dtype=resource>, <tf.Tensor 'unknown_67:0' shape=() dtype=resource>, <tf.Tensor 'unknown_68:0' shape=() dtype=resource>, <tf.Tensor 'unknown_69:0' shape=() dtype=resource>, <tf.Tensor 'unknown_70:0' shape=() dtype=resource>, <tf.Tensor 'unknown_71:0' shape=() dtype=resource>, <tf.Tensor 'unknown_72:0' shape=() dtype=resource>, <tf.Tensor 'unknown_73:0' shape=() dtype=resource>, <tf.Tensor 'unknown_74:0' shape=() dtype=resource>, <tf.Tensor 'unknown_75:0' shape=() dtype=resource>, <tf.Tensor 'unknown_76:0' shape=() dtype=resource>, <tf.Tensor 'unknown_77:0' shape=() dtype=resource>, <tf.Tensor 'unknown_78:0' shape=() dtype=resource>, <tf.Tensor 'unknown_79:0' shape=() dtype=resource>, <tf.Tensor 'unknown_80:0' shape=() dtype=resource>, <tf.Tensor 'unknown_81:0' shape=() dtype=resource>, <tf.Tensor 'unknown_82:0' shape=() dtype=resource>, <tf.Tensor 'unknown_83:0' shape=() dtype=resource>, <tf.Tensor 'unknown_84:0' shape=() dtype=resource>, <tf.Tensor 'unknown_85:0' shape=() dtype=resource>, <tf.Tensor 'unknown_86:0' shape=() dtype=resource>, <tf.Tensor 'unknown_87:0' shape=() dtype=resource>, <tf.Tensor 'unknown_88:0' shape=() dtype=resource>, <tf.Tensor 'unknown_89:0' shape=() dtype=resource>, <tf.Tensor 'unknown_90:0' shape=() dtype=resource>, <tf.Tensor 'unknown_91:0' shape=() dtype=resource>, <tf.Tensor 'unknown_92:0' shape=() dtype=resource>, <tf.Tensor 'unknown_93:0' shape=() dtype=resource>, <tf.Tensor 'unknown_94:0' shape=() dtype=resource>, <tf.Tensor 'unknown_95:0' shape=() dtype=resource>, <tf.Tensor 'unknown_96:0' shape=() dtype=resource>, <tf.Tensor 'unknown_97:0' shape=() dtype=resource>, <tf.Tensor 'unknown_98:0' shape=() dtype=resource>, <tf.Tensor 'unknown_99:0' shape=() dtype=resource>, <tf.Tensor 'unknown_100:0' shape=() dtype=resource>, <tf.Tensor 'unknown_101:0' shape=() dtype=resource>, <tf.Tensor 'unknown_102:0' shape=() dtype=resource>, <tf.Tensor 'unknown_103:0' shape=() dtype=resource>, <tf.Tensor 'unknown_104:0' shape=() dtype=resource>, <tf.Tensor 'unknown_105:0' shape=() dtype=resource>, <tf.Tensor 'unknown_106:0' shape=() dtype=resource>, <tf.Tensor 'unknown_107:0' shape=() dtype=resource>, <tf.Tensor 'unknown_108:0' shape=() dtype=resource>, <tf.Tensor 'unknown_109:0' shape=() dtype=resource>, <tf.Tensor 'unknown_110:0' shape=() dtype=resource>, <tf.Tensor 'unknown_111:0' shape=() dtype=resource>, <tf.Tensor 'unknown_112:0' shape=() dtype=resource>, <tf.Tensor 'unknown_113:0' shape=() dtype=resource>, <tf.Tensor 'unknown_114:0' shape=() dtype=resource>, <tf.Tensor 'unknown_115:0' shape=() dtype=resource>, <tf.Tensor 'unknown_116:0' shape=() dtype=resource>, <tf.Tensor 'unknown_117:0' shape=() dtype=resource>, <tf.Tensor 'unknown_118:0' shape=() dtype=resource>, <tf.Tensor 'unknown_119:0' shape=() dtype=resource>, <tf.Tensor 'unknown_120:0' shape=() dtype=resource>, <tf.Tensor 'unknown_121:0' shape=() dtype=resource>, <tf.Tensor 'unknown_122:0' shape=() dtype=resource>, <tf.Tensor 'unknown_123:0' shape=() dtype=resource>, <tf.Tensor 'unknown_124:0' shape=() dtype=resource>, <tf.Tensor 'unknown_125:0' shape=() dtype=resource>, <tf.Tensor 'unknown_126:0' shape=() dtype=resource>, <tf.Tensor 'unknown_127:0' shape=() dtype=resource>, <tf.Tensor 'unknown_128:0' shape=() dtype=resource>, <tf.Tensor 'unknown_129:0' shape=() dtype=resource>, <tf.Tensor 'unknown_130:0' shape=() dtype=resource>, <tf.Tensor 'unknown_131:0' shape=() dtype=resource>, <tf.Tensor 'unknown_132:0' shape=() dtype=resource>, <tf.Tensor 'unknown_133:0' shape=() dtype=resource>, <tf.Tensor 'unknown_134:0' shape=() dtype=resource>, <tf.Tensor 'unknown_135:0' shape=() dtype=resource>, <tf.Tensor 'unknown_136:0' shape=() dtype=resource>, <tf.Tensor 'unknown_137:0' shape=() dtype=resource>, <tf.Tensor 'unknown_138:0' shape=() dtype=resource>, <tf.Tensor 'unknown_139:0' shape=() dtype=resource>, <tf.Tensor 'unknown_140:0' shape=() dtype=resource>, <tf.Tensor 'unknown_141:0' shape=() dtype=resource>, <tf.Tensor 'unknown_142:0' shape=() dtype=resource>, <tf.Tensor 'unknown_143:0' shape=() dtype=resource>, <tf.Tensor 'unknown_144:0' shape=() dtype=resource>, <tf.Tensor 'unknown_145:0' shape=() dtype=resource>, <tf.Tensor 'unknown_146:0' shape=() dtype=resource>, <tf.Tensor 'unknown_147:0' shape=() dtype=resource>, <tf.Tensor 'unknown_148:0' shape=() dtype=resource>, <tf.Tensor 'unknown_149:0' shape=() dtype=resource>, <tf.Tensor 'unknown_150:0' shape=() dtype=resource>, <tf.Tensor 'unknown_151:0' shape=() dtype=resource>, <tf.Tensor 'unknown_152:0' shape=() dtype=resource>, <tf.Tensor 'unknown_153:0' shape=() dtype=resource>, <tf.Tensor 'unknown_154:0' shape=() dtype=resource>, <tf.Tensor 'unknown_155:0' shape=() dtype=resource>, <tf.Tensor 'unknown_156:0' shape=() dtype=resource>, <tf.Tensor 'unknown_157:0' shape=() dtype=resource>, <tf.Tensor 'unknown_158:0' shape=() dtype=resource>, <tf.Tensor 'unknown_159:0' shape=() dtype=resource>, <tf.Tensor 'unknown_160:0' shape=() dtype=resource>, <tf.Tensor 'unknown_161:0' shape=() dtype=resource>, <tf.Tensor 'unknown_162:0' shape=() dtype=resource>, <tf.Tensor 'unknown_163:0' shape=() dtype=resource>, <tf.Tensor 'unknown_164:0' shape=() dtype=resource>, <tf.Tensor 'unknown_165:0' shape=() dtype=resource>, <tf.Tensor 'unknown_166:0' shape=() dtype=resource>, <tf.Tensor 'unknown_167:0' shape=() dtype=resource>, <tf.Tensor 'unknown_168:0' shape=() dtype=resource>, <tf.Tensor 'unknown_169:0' shape=() dtype=resource>, <tf.Tensor 'unknown_170:0' shape=() dtype=resource>, <tf.Tensor 'unknown_171:0' shape=() dtype=resource>, <tf.Tensor 'unknown_172:0' shape=() dtype=resource>, <tf.Tensor 'unknown_173:0' shape=() dtype=resource>, <tf.Tensor 'unknown_174:0' shape=() dtype=resource>, <tf.Tensor 'unknown_175:0' shape=() dtype=resource>, <tf.Tensor 'unknown_176:0' shape=() dtype=resource>, <tf.Tensor 'unknown_177:0' shape=() dtype=resource>, <tf.Tensor 'unknown_178:0' shape=() dtype=resource>, <tf.Tensor 'unknown_179:0' shape=() dtype=resource>, <tf.Tensor 'unknown_180:0' shape=() dtype=resource>, <tf.Tensor 'unknown_181:0' shape=() dtype=resource>, <tf.Tensor 'unknown_182:0' shape=() dtype=resource>, <tf.Tensor 'unknown_183:0' shape=() dtype=resource>, <tf.Tensor 'unknown_184:0' shape=() dtype=resource>, <tf.Tensor 'unknown_185:0' shape=() dtype=resource>, <tf.Tensor 'unknown_186:0' shape=() dtype=resource>, <tf.Tensor 'unknown_187:0' shape=() dtype=resource>, <tf.Tensor 'unknown_188:0' shape=() dtype=resource>, <tf.Tensor 'unknown_189:0' shape=() dtype=resource>, <tf.Tensor 'unknown_190:0' shape=() dtype=resource>, <tf.Tensor 'unknown_191:0' shape=() dtype=resource>, <tf.Tensor 'unknown_192:0' shape=() dtype=resource>, <tf.Tensor 'unknown_193:0' shape=() dtype=resource>, <tf.Tensor 'unknown_194:0' shape=() dtype=resource>, <tf.Tensor 'unknown_195:0' shape=() dtype=resource>, <tf.Tensor 'unknown_196:0' shape=() dtype=resource>, <tf.Tensor 'unknown_197:0' shape=() dtype=resource>, <tf.Tensor 'unknown_198:0' shape=() dtype=resource>, <tf.Tensor 'unknown_199:0' shape=() dtype=resource>, <tf.Tensor 'unknown_200:0' shape=() dtype=resource>, <tf.Tensor 'unknown_201:0' shape=() dtype=resource>, <tf.Tensor 'unknown_202:0' shape=() dtype=resource>, <tf.Tensor 'unknown_203:0' shape=() dtype=resource>, <tf.Tensor 'unknown_204:0' shape=() dtype=resource>, <tf.Tensor 'unknown_205:0' shape=() dtype=resource>, <tf.Tensor 'unknown_206:0' shape=() dtype=resource>, <tf.Tensor 'unknown_207:0' shape=() dtype=resource>, <tf.Tensor 'unknown_208:0' shape=() dtype=resource>, <tf.Tensor 'unknown_209:0' shape=() dtype=resource>, <tf.Tensor 'unknown_210:0' shape=() dtype=resource>, <tf.Tensor 'unknown_211:0' shape=() dtype=resource>, <tf.Tensor 'unknown_212:0' shape=() dtype=resource>, <tf.Tensor 'unknown_213:0' shape=() dtype=resource>, <tf.Tensor 'unknown_214:0' shape=() dtype=resource>, <tf.Tensor 'unknown_215:0' shape=() dtype=resource>, <tf.Tensor 'unknown_216:0' shape=(2,) dtype=float32>, <tf.Tensor 'unknown_217:0' shape=(2,) dtype=float32>, <tf.Tensor 'unknown_218:0' shape=(2,) dtype=float32>, <tf.Tensor 'unknown_219:0' shape=() dtype=resource>, <tf.Tensor 'unknown_220:0' shape=() dtype=resource>, <tf.Tensor 'unknown_221:0' shape=() dtype=resource>, <tf.Tensor 'unknown_222:0' shape=() dtype=resource>, <tf.Tensor 'unknown_223:0' shape=() dtype=resource>, <tf.Tensor 'unknown_224:0' shape=() dtype=resource>, <tf.Tensor 'unknown_225:0' shape=() dtype=resource>, <tf.Tensor 'unknown_226:0' shape=() dtype=resource>, <tf.Tensor 'unknown_227:0' shape=() dtype=resource>, <tf.Tensor 'unknown_228:0' shape=() dtype=resource>, <tf.Tensor 'unknown_229:0' shape=() dtype=resource>, <tf.Tensor 'unknown_230:0' shape=() dtype=resource>, <tf.Tensor 'unknown_231:0' shape=() dtype=resource>, <tf.Tensor 'unknown_232:0' shape=() dtype=resource>, <tf.Tensor 'unknown_233:0' shape=() dtype=resource>, <tf.Tensor 'unknown_234:0' shape=() dtype=resource>, <tf.Tensor 'unknown_235:0' shape=() dtype=resource>, <tf.Tensor 'unknown_236:0' shape=() dtype=resource>, <tf.Tensor 'unknown_237:0' shape=() dtype=resource>, <tf.Tensor 'unknown_238:0' shape=() dtype=resource>, <tf.Tensor 'unknown_239:0' shape=() dtype=resource>, <tf.Tensor 'unknown_240:0' shape=() dtype=resource>, <tf.Tensor 'unknown_241:0' shape=() dtype=resource>, <tf.Tensor 'unknown_242:0' shape=() dtype=resource>, <tf.Tensor 'unknown_243:0' shape=() dtype=resource>, <tf.Tensor 'unknown_244:0' shape=() dtype=resource>, <tf.Tensor 'unknown_245:0' shape=() dtype=resource>, <tf.Tensor 'unknown_246:0' shape=() dtype=resource>, <tf.Tensor 'unknown_247:0' shape=() dtype=resource>, <tf.Tensor 'unknown_248:0' shape=() dtype=resource>, <tf.Tensor 'unknown_249:0' shape=() dtype=resource>, <tf.Tensor 'unknown_250:0' shape=() dtype=resource>, <tf.Tensor 'unknown_251:0' shape=() dtype=resource>, <tf.Tensor 'unknown_252:0' shape=() dtype=resource>, <tf.Tensor 'unknown_253:0' shape=() dtype=resource>, <tf.Tensor 'unknown_254:0' shape=() dtype=resource>, <tf.Tensor 'unknown_255:0' shape=() dtype=resource>, <tf.Tensor 'unknown_256:0' shape=() dtype=resource>, <tf.Tensor 'unknown_257:0' shape=() dtype=resource>, <tf.Tensor 'unknown_258:0' shape=() dtype=resource>, <tf.Tensor 'unknown_259:0' shape=() dtype=resource>, <tf.Tensor 'unknown_260:0' shape=() dtype=resource>, <tf.Tensor 'unknown_261:0' shape=() dtype=resource>, <tf.Tensor 'unknown_262:0' shape=() dtype=resource>, <tf.Tensor 'unknown_263:0' shape=() dtype=resource>, <tf.Tensor 'unknown_264:0' shape=() dtype=resource>, <tf.Tensor 'unknown_265:0' shape=() dtype=resource>, <tf.Tensor 'unknown_266:0' shape=() dtype=resource>, <tf.Tensor 'unknown_267:0' shape=() dtype=resource>, <tf.Tensor 'unknown_268:0' shape=() dtype=resource>, <tf.Tensor 'unknown_269:0' shape=() dtype=resource>, <tf.Tensor 'unknown_270:0' shape=() dtype=resource>, <tf.Tensor 'unknown_271:0' shape=() dtype=resource>, <tf.Tensor 'unknown_272:0' shape=() dtype=resource>, <tf.Tensor 'unknown_273:0' shape=() dtype=resource>, <tf.Tensor 'unknown_274:0' shape=() dtype=resource>, <tf.Tensor 'unknown_275:0' shape=() dtype=resource>, <tf.Tensor 'unknown_276:0' shape=() dtype=resource>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detection_model.signatures['serving_default'].output_dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzvp4O5imZwL",
        "outputId": "a91b679b-929f-43fb-8eec-7a30c2a18432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'detection_anchor_indices': tf.float32,\n",
              " 'detection_boxes': tf.float32,\n",
              " 'detection_classes': tf.float32,\n",
              " 'detection_multiclass_scores': tf.float32,\n",
              " 'detection_scores': tf.float32,\n",
              " 'num_detections': tf.float32,\n",
              " 'raw_detection_boxes': tf.float32,\n",
              " 'raw_detection_scores': tf.float32}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detection_model.signatures['serving_default'].output_shapes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCxjLkyZmjur",
        "outputId": "c212f6b0-247e-43b7-85c2-fbcf6a282746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'detection_anchor_indices': TensorShape([1, 300]),\n",
              " 'detection_boxes': TensorShape([1, 300, 4]),\n",
              " 'detection_classes': TensorShape([1, 300]),\n",
              " 'detection_multiclass_scores': TensorShape([1, 300, 3]),\n",
              " 'detection_scores': TensorShape([1, 300]),\n",
              " 'num_detections': TensorShape([1]),\n",
              " 'raw_detection_boxes': TensorShape([1, 300, 4]),\n",
              " 'raw_detection_scores': TensorShape([1, 300, 3])}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP5qZ7sXJpwG"
      },
      "source": [
        "Then, we will add a wrapper function to call the model, and cleanup the outputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajmR_exWyN76"
      },
      "outputs": [],
      "source": [
        "def run_inference_for_single_image(model, image):\n",
        "  image = np.asarray(image)\n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\n",
        "\n",
        "  # Run inference\n",
        "  model_fn = model.signatures['serving_default']\n",
        "  output_dict = model_fn(input_tensor)\n",
        "\n",
        "  # All outputs are batches tensors.\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "  # We're only interested in the first num_detections.\n",
        "  num_detections = int(output_dict.pop('num_detections'))\n",
        "  output_dict = {key:value[0, :num_detections].numpy()\n",
        "                 for key,value in output_dict.items()}\n",
        "  output_dict['num_detections'] = num_detections\n",
        "\n",
        "  # detection_classes should be ints.\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "\n",
        "  # Handle models with masks:\n",
        "  if 'detection_masks' in output_dict:\n",
        "    # Reframe the the bbox mask to the image size.\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "               image.shape[0], image.shape[1])\n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                       tf.uint8)\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "\n",
        "  return output_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1wq0LVyMRR_"
      },
      "source": [
        "Run it on the selected test image and output the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWh_1zz6aqxs"
      },
      "outputs": [],
      "source": [
        "def show_inference(model, image_path):\n",
        "  # the array based representation of the image will be used later in order to prepare the\n",
        "  # result image with boxes and labels on it.\n",
        "  image_np = np.array(Image.open(image_path))\n",
        "  # Actual detection.\n",
        "  output_dict = run_inference_for_single_image(model, image_np)\n",
        "  # Visualization of the results of a detection.\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8)\n",
        "\n",
        "  display(Image.fromarray(image_np))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a5wMHN8WKMh"
      },
      "outputs": [],
      "source": [
        "for image_path in TEST_IMAGE_PATHS:\n",
        "  show_inference(detection_model, image_path)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}